interpreter = tf.lite.Interpreter(model_path="model.tflite")
interpreter.allocate_tensors()
# Run inference and compare predictions to ground truth
